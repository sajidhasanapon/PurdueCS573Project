{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CS 573 Our Model.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"2oLlb6Fk-p1f","colab_type":"text"},"source":["## Download and extract the dataset\n","---\n","### Download link expires on December 18, 2019"]},{"cell_type":"code","metadata":{"id":"8T9tfrruNMGH","colab_type":"code","outputId":"531f069a-6318-4dca-a2b9-3fb8e086a060","executionInfo":{"status":"ok","timestamp":1575591988644,"user_tz":300,"elapsed":10973,"user":{"displayName":"Sajid Hasan Apon","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDppOr3e0-6U7IibiOE83rDlBfUTzhcAdaZj9B3uQ=s64","userId":"03684353269636747183"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# !rm -r *\n","# !wget https://transfer.sh/Lpw1d/dataset.zip\n","!unzip -q dataset.zip\n","!ls -l --block-size=M"],"execution_count":0,"outputs":[{"output_type":"stream","text":["total 927M\n","-rw-r--r-- 1 root root 719M Dec  5 06:52 dataset.csv\n","-rw-r--r-- 1 root root 209M Dec  6 00:25 dataset.zip\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9P9VDpuK-MMr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":80},"outputId":"053a2b67-5a44-435e-ec59-ff5252b0d5aa","executionInfo":{"status":"ok","timestamp":1575762952214,"user_tz":300,"elapsed":3025,"user":{"displayName":"Sajid Hasan Apon","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDppOr3e0-6U7IibiOE83rDlBfUTzhcAdaZj9B3uQ=s64","userId":"03684353269636747183"}}},"source":["# Libraries\n","import pandas as pd\n","import numpy as np\n","import keras\n","from keras.callbacks import *\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n","from keras import optimizers\n","from sklearn.model_selection import train_test_split, KFold"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"kLtMoLFuEBqD","colab_type":"code","colab":{}},"source":["# Load Data\n","dataset = np.loadtxt(fname=\"dataset.csv\", delimiter=\",\", skiprows=1)\n","n_samples = dataset.shape[0]\n","\n","X = dataset[:, :-1]\n","y = dataset[:, -1]\n","\n","# Reshape the array into 28 x 28 pixel\n","X = X.reshape(n_samples, 28, 28, 1)\n","# Normalize the data\n","X = X / 255.0\n","\n","y = keras.utils.to_categorical(y, 122)\n","\n","#train-test split\n","X_train_all, X_test, y_train_all, y_test = train_test_split(X, y, test_size=0.1, random_state=1337, shuffle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wa4zu-gOivIW","colab_type":"text"},"source":["# Training LeNet\n"]},{"cell_type":"code","metadata":{"id":"Lsoi35MBD8F5","colab_type":"code","colab":{}},"source":["def get_model(optimizer_name, learning_rate, loss_func_name):\n","    model = Sequential()\n","\n","    model.add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28, 28, 1)))\n","    model.add(Conv2D(32, kernel_size = 3, activation='relu'))\n","    model.add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n","    # model.add(Dropout(0.4))\n","\n","    model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n","    model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n","    model.add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n","    # model.add(Dropout(0.4))\n","\n","    model.add(Conv2D(128, kernel_size = 4, activation='relu'))\n","\n","    model.add(Flatten())\n","    # model.add(Dropout(0.4))\n","    model.add(Dense(122, activation='softmax'))\n","\n","    optimizer = None\n","    if optimizer_name == \"adam\":\n","        optimizer = optimizers.Adam(lr=learning_rate)\n","    elif optimizer_name == \"sgd\":\n","        optimizer = optimizers.SGD(lr=learning_rate)\n","\n","    model.compile(optimizer=optimizer, loss=loss_func_name, metrics=[\"accuracy\"])\n","\n","    return model\n","\n","\n","\n","k = 10\n","n_epochs = 15\n","callbacks = [EarlyStopping(monitor=\"acc\", patience=2)]\n","\n","for optimizer_name in [\"adam\", \"sgd\"]:\n","    for learning_rate in [0.001, 0.01]:\n","        for batch_size in [32, 64]:\n","\n","            model_name = optimizer_name + \"_\" + str(batch_size) + \"_\" + str(learning_rate)\n","            print(model_name, end=\"...   \")\n","            val_acc_list = []\n","            kf = KFold(n_splits=k)\n","\n","            # for train_index, test_index in kf.split(X_train_all):\n","            #     X_train, X_val = X_train_all[train_index], X_train_all[test_index]\n","            #     y_train, y_val = y_train_all[train_index], y_train_all[test_index]\n","\n","            #     model = get_model(optimizer_name, learning_rate)\n","            #     model.fit(X_train, y_train, epochs=n_epochs, batch_size=batch_size, verbose=0, callbacks=callbacks)\n","            #     loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n","            #     val_acc_list.append(val_acc)\n","\n","            model = get_model(optimizer_name, learning_rate, \"categorical_crossentropy\")\n","            model.fit(X_train_all, y_train_all, epochs=n_epochs, batch_size=batch_size, verbose=1, callbacks=callbacks)\n","            # loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n","            loss, val_acc = model.evaluate(X_train_all, y_train_all, verbose=1)\n","            val_acc_list.append(val_acc)\n","\n","            logger = open(\"log.txt\", \"a\")\n","            # print(model_name, np.mean(val_acc_list), np.std(val_acc_list), file=logger)\n","            print(model_name, np.mean(val_acc_list), file=logger)\n","            print(\"mean_val_acc:\", np.mean(val_acc_list), \"  std_deviation:\", np.std(val_acc_list))\n","            logger.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4rkQreH2IXnu","colab_type":"code","colab":{}},"source":["model = get_model(\"adam\", 0.001)\n","model.fit(X_train_all, y_train_all, epochs=20, batch_size=64, verbose=1, callbacks=callbacks)\n","model.evaluate(X_test, y_test, verbose = 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SzHTyUQXlAoQ","colab_type":"code","colab":{}},"source":["# from google.colab import files\n","# files.download('log.txt') "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MYCgfJvgyr-b","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":666},"outputId":"7eac8b53-bc82-433d-aa55-55fd23211c30","executionInfo":{"status":"ok","timestamp":1575763086196,"user_tz":300,"elapsed":1366,"user":{"displayName":"Sajid Hasan Apon","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDppOr3e0-6U7IibiOE83rDlBfUTzhcAdaZj9B3uQ=s64","userId":"03684353269636747183"}}},"source":["def get_model(optimizer_name, learning_rate, loss_func_name):\n","    model = Sequential()\n","\n","    model.add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28, 28, 1)))\n","    model.add(Conv2D(32, kernel_size = 3, activation='relu'))\n","    model.add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n","    model.add(Dropout(0.4))\n","\n","    model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n","    model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n","    model.add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n","    model.add(Dropout(0.4))\n","\n","    model.add(Conv2D(128, kernel_size = 4, activation='relu'))\n","\n","    model.add(Flatten())\n","    model.add(Dropout(0.4))\n","    model.add(Dense(122, activation='softmax'))\n","\n","    optimizer = None\n","    if optimizer_name == \"adam\":\n","        optimizer = optimizers.Adam(lr=learning_rate)\n","    elif optimizer_name == \"sgd\":\n","        optimizer = optimizers.SGD(lr=learning_rate)\n","\n","    model.compile(optimizer=optimizer, loss=loss_func_name, metrics=[\"accuracy\"])\n","\n","    return model\n","\n","model = get_model(\"adam\", 0.001, \"categorical_crossentropy\")\n","model.summary()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_8 (Conv2D)            (None, 26, 26, 32)        320       \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 24, 24, 32)        9248      \n","_________________________________________________________________\n","conv2d_10 (Conv2D)           (None, 12, 12, 32)        25632     \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n","_________________________________________________________________\n","conv2d_11 (Conv2D)           (None, 10, 10, 64)        18496     \n","_________________________________________________________________\n","conv2d_12 (Conv2D)           (None, 8, 8, 64)          36928     \n","_________________________________________________________________\n","conv2d_13 (Conv2D)           (None, 4, 4, 64)          102464    \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 4, 4, 64)          0         \n","_________________________________________________________________\n","conv2d_14 (Conv2D)           (None, 1, 1, 128)         131200    \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 128)               0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 122)               15738     \n","=================================================================\n","Total params: 340,026\n","Trainable params: 340,026\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"piG0AhiHy2y5","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}